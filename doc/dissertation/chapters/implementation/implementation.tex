\chapter{Implementation}
The work is split into four modules, or what Isabelle calls \emph{theories}.
The first (\emph{Fresh}) deals with fresh names and implementations of freshness, the second (\emph{Permutation}) with a theory of permutations, and the third and fourth (\emph{PreSimplyTyped} and \emph{SimplyTyped}) with \(\lambda\)-terms, before and after the quotient respectively.
All theories develop upon basic theorems shown in Isabelle's standard library, called \emph{Main}.
A dependency graph is shown in Figure \ref{fig:dependencies}.

\begin{figure}
\centering
\includegraphics[width=.5\textwidth]{chapters/implementation/figures/dependencies}
\caption{A directed graph showing which of the theories depend on each other. \(A \to B\) shows that \(B\) depends upon results in \(A\).}
\label{fig:dependencies}
\end{figure}

\section{Freshness}
I first develop a theory of fresh name generation, used later in arguments about fresh names in a given \(\lambda\)-term.
The implementation should take a set (of some type, since we wish to be parametric) and produce an element not in that set.
In order to specify an interface over an arbitrary type, I used Isabelle's typeclass mechanism~\cite{isabelle-typeclasses} to make a class (i.e. an interface) for types that can produce a fresh element from a set:

\begin{implementation}
\isacommand{class}\isamarkupfalse%
\ fresh\ =\isanewline
\ \ \isakeyword{fixes}\ fresh{\isacharunderscore}in\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ set\ {\isasymRightarrow}\ {\isacharprime}a{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}finite\ S\ {\isasymLongrightarrow}\ fresh{\isacharunderscore}in\ S\ {\isasymnotin}\ S{\isachardoublequoteclose}\isanewline
\end{implementation}

Note the pre-condition of \(S\) being a finite set: otherwise, many useful implementations (such as that of numbers, or finite strings) cannot conform to this interface.
To see this, consider (possibly-infinite) sets \(S\) of natural numbers.
Since \(S\) can be infinite, choose \(S\) to be \(\mathbb{N}\), the set of all natural numbers.
Now, if \(x\) is to be fresh in \(S\), \(x\) must be a natural number.
But since \(x \notin S\), \(x\) must also \emph{not} be a natural number, since \(S = \mathbb{N}\) --- hence, a contradiction.
As a result, sets used to generate a fresh variable must be finite.

It is now possible to argue about fresh sets in later developments.
However, to extract executable code, then there must be at least one implementation of this specification of freshness.
Unfortunately, not any implementation will do: for instance, Isabelle allows use of the Hilbert indefinite description operator \(\epsilon\) in definitions.
Hilbert's operator is a form of \emph{choice principle} --- the semantics of which are (roughly) ``assuming that there is at least one \(x\) such that \(P(x)\), \(\epsilon x. P(x)\) chooses one such \(x\) and produces its value'' --- so
\[
\epsilon x. x \notin S
\]
would be a perfectly valid (and logical) definition of freshness for any instance for which you could prove there was such an \(x\) --- but this definition is not executable, and hence code cannot be extracted from it.
Natural numbers provide a straightforward interface to define an \emph{executable} freshness algorithm for: to make a fresh natural number from a finite set \(S\), take the largest element of the set, then add 1 to it (in the case of the empty set, produce 0).

\begin{implementation}
\isacommand{instantiation}\isamarkupfalse%
\ nat\ {\isacharcolon}{\isacharcolon}\ fresh\isanewline
\isakeyword{begin}\isanewline
\ \ \isacommand{definition}\isamarkupfalse%
\ fresh{\isacharunderscore}in{\isacharunderscore}nat\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}nat\ set\ {\isasymRightarrow}\ nat{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ \ \ {\isacharbrackleft}code{\isacharbrackright}{\isacharcolon}\ {\isachardoublequoteopen}fresh{\isacharunderscore}in{\isacharunderscore}nat\ S\ {\isasymequiv}\ {\isacharparenleft}if\ Set{\isachardot}is{\isacharunderscore}empty\ S\ then\ {\isadigit{0}}\ else\ Max\ S\ {\isacharplus}\ {\isadigit{1}}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

The above also generates a proof obligation to show that this satisfies the freshness specification.

\begin{lemma}
For any finite set \(S\) of natural numbers, the procedure above produces a number \(n\) such that \(n \notin S\).
\end{lemma}
\begin{proof}
\(S\) is either the empty set, or it is not.
If \(S\) is empty, 0 is produced as fresh in \(S\).
\(0 \notin S\) by definition of the empty set.
If \(S\) is non-empty, then \(n'\) is produced such that \(n'\) is one more (i.e. strictly larger) than the largest element of \(S\), \(n\).
Suppose for contradiction that \(n'\) were in \(S\).
Then \(n'\) would be the largest element of \(S\), not \(n\).
Hence \(n'\) must not be in \(S\).
\end{proof}

\section{Swappings and Permutations}
Swappings are used in the nominal definition of \(\alpha\)-equivalence, seen later.
While using this definition, applications of swappings can build up, and need reducing; for example, applying any given swapping twice is the same operation as not applying any swappings at all --- that is, application of swappings is an \emph{involutive} operation.
While these rules can be argued only in the context of sequences of swapping application, it is more convenient to allow for composition of swappings into \emph{permutations}.
Simple equality here will not suffice either: permutations are equal iff they have the same effect on all inputs.
This is another use case for the quotient type mechanism: by identifying permutations that are extensionally, but not intensionally, equal, a new type can be made that does not make this distinction.

Therefore, I proceed by first defining swappings, then \emph{pre-permutations}, then later produce \emph{permutations}.

\begin{implementation}
\isacommand{type{\isacharunderscore}synonym}\isamarkupfalse%
\ {\isacharprime}a\ swp\ =\ {\isachardoublequoteopen}{\isacharprime}a\ {\isasymtimes}\ {\isacharprime}a{\isachardoublequoteclose}\isanewline
\isacommand{type{\isacharunderscore}synonym}\isamarkupfalse%
\ {\isacharprime}a\ preprm\ =\ {\isachardoublequoteopen}{\isacharprime}a\ swp\ list{\isachardoublequoteclose}\isanewline
\end{implementation}

The identity permutation \(\varepsilon\) is then defined to be the empty list: as mentioned, this is not the only possible implementation (consider \([\wrap{a, a}]\) --- swapping any name for itself in an object always produces the same object), but at least one is required for later use as the quotient identity.

\begin{implementation}
\isacommand{definition}\isamarkupfalse%
\ preprm{\isacharunderscore}id\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ preprm{\isachardoublequoteclose}\ \isakeyword{where}\ {\isachardoublequoteopen}preprm{\isacharunderscore}id\ =\ {\isacharbrackleft}{\isacharbrackright}{\isachardoublequoteclose}\isanewline
\end{implementation}

Converting a swapping into a permutation can be done by placing the swapping inside a list of its own --- then, it still has the effect of the original swapping, but is a permutation.

\begin{implementation}
\isacommand{definition}\isamarkupfalse%
\ preprm{\isacharunderscore}unit\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ {\isacharprime}a\ preprm{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}preprm{\isacharunderscore}unit\ a\ b\ {\isasymequiv}\ {\isacharbrackleft}{\isacharparenleft}a,\ b{\isacharparenright}{\isacharbrackright}{\isachardoublequoteclose}\isanewline
\end{implementation}

\begin{definition}
Application of pre-permutations to variables, \(\pi \dollar x\), is defined as follows.
\begin{enumerate}
\item
\(\varepsilon \dollar x = x\)
\item
Applying the sequence \(\wrap{a, b} :: \pi'\) to \(x\) is the same as applying \(\wrap{a, b}\) to \(\pi' \dollar x\), since \(\pi'\) is applied first, then \(\wrap{a, b}\) is applied to the result.
\end{enumerate}
\end{definition}

\begin{implementation}
\isacommand{fun}\isamarkupfalse%
\ swp{\isacharunderscore}apply\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ swp\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ {\isacharprime}a{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}swp{\isacharunderscore}apply\ {\isacharparenleft}a,\ b{\isacharparenright}\ x\ =\ {\isacharparenleft}if\ x\ =\ a\ then\ b\ else\ {\isacharparenleft}if\ x\ =\ b\ then\ a\ else\ x{\isacharparenright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{fun}\isamarkupfalse%
\ preprm{\isacharunderscore}apply\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ preprm\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ {\isacharprime}a{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}preprm{\isacharunderscore}apply\ {\isacharbrackleft}{\isacharbrackright}\ x\ =\ x{\isachardoublequoteclose}\isanewline
{\isacharbar}\ {\isachardoublequoteopen}preprm{\isacharunderscore}apply\ {\isacharparenleft}s\ {\isacharhash}\ ss{\isacharparenright}\ x\ {\isacharequal}\ swp{\isacharunderscore}apply\ s\ {\isacharparenleft}preprm{\isacharunderscore}apply\ ss\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

From this definition, we can show that the defined identity element is in fact identity.

\begin{lemma}
\label{lemma:identity-application}
\(\varepsilon\) has the property \(\varepsilon \dollar x = x\), for any \(x\).
\end{lemma}
\begin{proof}
By definition of application.
\end{proof}

In later proofs about the \(\alpha\)-equivalence of binders, it's useful to be able to argue both that \(x = y \Longrightarrow \pi \dollar x = \pi \dollar y\) (which follows from identity), its inverse, \(x \neq y \Longrightarrow \pi \dollar x \neq \pi \dollar y\), and the converse, \(\pi \dollar x = \pi \dollar y \Longrightarrow x = y\) (i.e. that permutation application is injective).

\begin{lemma}
\label{lemma:apply-unequal}
If \(x \neq y\), then \(\pi \dollar x \neq \pi \dollar y\)
\end{lemma}
\begin{proof}
By induction on \(\pi\).
The base case is easy using Lemma \ref{lemma:identity-application}, as by assumption \(x \neq y\).
For the inductive step, suppose \(x' \neq y'\).
Then \([\wrap{a, b}] \dollar x' \neq [\wrap{a, b}] \dollar y'\), by cases on \(x'\) and \(y'\).
\end{proof}

\begin{lemma}
Application of permutations \(\pi\) is injective.
\end{lemma}
\begin{proof}
By induction on \(\pi\).
The base case follows by definition.
Using the inductive hypothesis, have that \([(a, b)] \dollar \wrap{\pi' \dollar x} = [(a, b)] \dollar \wrap{\pi' \dollar y}\).
Then use the contrapositive of Lemma \ref{lemma:apply-unequal} to show that \(x = y\) using the inductive hypothesis.
\end{proof}

There are a couple of other useful operations on pre-permutations that are defined on the pre-permutations, then lifted over the equivalence relation.

\begin{definition}
The composite pre-permutation \(\pi \diamond \sigma\) is the sequence \(\sigma\) appended to the sequence \(\pi\) to create a new sequence.
\end{definition}
Therefore, composition can be implemented as a list-append operation.

\begin{implementation}
\isacommand{definition}\isamarkupfalse%
\ preprm{\isacharunderscore}compose\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ preprm\ {\isasymRightarrow}\ {\isacharprime}a\ preprm\ {\isasymRightarrow}\ {\isacharprime}a\ preprm{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}preprm{\isacharunderscore}compose\ f\ g\ {\isasymequiv}\ f\ {\isacharat}\ g{\isachardoublequoteclose}\isanewline
\end{implementation}

Permutation composition must behave as if it were function composition: otherwise, it's not a very good definition of ``composition''.

\begin{lemma}
\label{lemma:apply-composition}
Application of the composite permutation \(\pi \diamond \sigma\) is the same as applying first \(\sigma\), then \(\pi\).
\end{lemma}
\begin{proof}
By induction on \(\pi\).
Both cases then follow by definition.
\end{proof}

A common simplifying argument is to move swappings around until two are adjacent, since clearly swapping two things twice is the same as not swapping them at all.

\begin{lemma}
\label{lemma:unit-involution}
Composition of the unit permutation \([\wrap{a, b}]\) with itself is equivalent to the identity element.
\end{lemma}
\begin{proof}
Unfold the definition of equivalence, then consider whether \(x\), the variable the permutation is applied to, is \(a\), \(b\), or neither.
If it is \(a\) or \(b\), then swapping \(a\) to \(b\), then \(b\) to \(a\) (or vice-versa) produces the same \(x\).
If it is not, then the swapping has no effect, so two iterations of swapping still has no effect.
\end{proof}

\begin{definition}
The inverse of a permutation \(\pi\), \(\pi^{-1}\), is defined to be the reverse of the sequence of swappings \(\pi\) consists of.
\end{definition}

\begin{implementation}
\isacommand{definition}\isamarkupfalse%
\ preprm{\isacharunderscore}inv\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ preprm\ {\isasymRightarrow}\ {\isacharprime}a\ preprm{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}preprm{\isacharunderscore}inv\ {\isasympi}\ {\isasymequiv}\ rev\ {\isasympi}{\isachardoublequoteclose}\isanewline
\end{implementation}

It can be shown that this is in fact the inverse of a permutation as follows.
\begin{lemma}
\label{lemma:inverse-involution}
For any \(\pi\) and \(x\), \(\pi^{-1} \dollar \pi \dollar x = x\), and vice-versa, \(\pi \dollar \pi^{-1} \dollar x = x\).
\end{lemma}
\begin{proof}
By induction on \(\pi\), with a trivial base case.
For the inductive step, assume that \(\pi'^{-1} \dollar \pi' \dollar x = x\) and try to show
\[
\wrap{[\wrap{a, b}] \diamond \pi'}^{-1} \dollar \wrap{[\wrap{a, b}] \diamond \pi'} \dollar x = x
\]

Note that
\[
\wrap{[\wrap{a, b}] \diamond \pi'}^{-1} = \pi'^{-1} \diamond [\wrap{a, b}]
\]
by definition of inverse.
Hence, using Lemmas \ref{lemma:apply-composition} and \ref{lemma:unit-involution} and the inductive hypothesis,
\begin{align*}
\wrap{[\wrap{a, b}] \diamond \pi'}^{-1} \dollar \wrap{\wrap{[\wrap{a, b}] \diamond \pi'} \dollar x}
&= \wrap{\pi'^{-1} \diamond [\wrap{a, b}]} \dollar \wrap{\wrap{[\wrap{a, b}] \diamond \pi'} \dollar x}\\
&= \pi'^{-1} \dollar \wrap{[\wrap{a, b}] \diamond [\wrap{a, b}]} \dollar \pi' \dollar x\\
&= \pi'^{-1} \dollar \wrap{\varepsilon} \dollar \pi' \dollar x\\
&= \pi'^{-1} \dollar \pi' \dollar x\\
&= x\\
\end{align*}
as required.
The alternative proposition follows from this and the fact that \(\wrap{\pi^{-1}}^{-1} = \pi\), noting that reversing a list twice produces the original list.
\end{proof}

By using the definition of permutation application, I can define that permutations are equivalent when they are members of a relation, so I start by defining an extensional equivalence relation:

\begin{implementation}
\isacommand{definition}\isamarkupfalse%
\isanewline
\ \ preprm{\isacharunderscore}ext\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ preprm\ {\isasymRightarrow}\ {\isacharprime}a\ preprm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}{\isasympi}\ =p\ {\isasymsigma}\ {\isasymequiv}\ {\isasymforall}x{\isachardot}\ preprm{\isacharunderscore}apply\ {\isasympi}\ x\ =\ preprm{\isacharunderscore}apply\ {\isasymsigma}\ x{\isachardoublequoteclose}\isanewline
\end{implementation}

i.e. that \(\pi\) and \(\sigma\) are equivalent, \(\pi \equiv_p \sigma\),  when for any input \(x\) applying \(\pi\) and \(\sigma\) produces the same result.
This relation is in fact an equivalence relation:

\begin{lemma}
\(\equiv_p\) is an equivalence relation.
\end{lemma}
\begin{proof}
Unfolding the definition of equivalence, \(\equiv_p\) is trivially reflexive, symmetric, and transitive.
Therefore it is an equivalence relation.
\end{proof}

Several properties of composition and inverse under this equivalence behave as they would under equality as well.

\begin{lemma}
If \(\sigma \equiv_p \tau\), then \(\pi \diamond \sigma \equiv_p \pi \diamond \tau\).
\end{lemma}
\begin{lemma}
If \(\sigma \equiv_p \tau\), then \(\sigma \diamond \pi \equiv_p \tau \diamond \pi\).
\end{lemma}
\begin{proof}
Both of these follow from Lemma \ref{lemma:apply-composition}.
\end{proof}

\begin{lemma}
\label{lemma:uncompose}
If \(\pi \equiv_p \sigma\) and \(\pi \diamond \tau \equiv_p \sigma \diamond \rho\),
then \(\tau \equiv_p \rho\).
\end{lemma}
\begin{proof}
By assumption obtain \(\pi \diamond \tau \equiv_p \pi \diamond \rho\), then using the injectivity of permutation application, arrive at the result.
\end{proof}

\begin{lemma}
If \(\pi \equiv_p \sigma\), then \(\pi^{-1} \equiv_p \sigma^{-1}\).
\end{lemma}
\begin{proof}
Note that \(\wrap{\pi^{-1}}^{-1} \diamond \pi^{-1} \equiv_p \varepsilon\) and \(\wrap{\sigma^{-1}}^{-1} \diamond \sigma^{-1} \equiv_p \varepsilon\), using Lemma \ref{lemma:inverse-involution}.
Hence \(\pi \diamond \pi^{-1} \equiv_p \varepsilon\), and correspondingly for \(\sigma\).
From these obtain \(\pi \diamond \pi^{-1} \equiv_p \sigma \diamond \sigma^{-1}\), since \(\equiv_p\) is an equivalence relation.
Finally, derive the result by applying Lemma \ref{lemma:uncompose} and the assumptions.
\end{proof}

It is also algebraically interesting to note that composition with an inverse also produces identity.
\begin{lemma}
\label{lemma:group-inverse}
For any \(\pi\), \(\pi^{-1} \diamond \pi \equiv_p \varepsilon\).
\end{lemma}
\begin{proof}
Using Lemmas \ref{lemma:inverse-involution} and \ref{lemma:apply-composition}, this follows directly.
\end{proof}

The preceding theory about permutations and how application, composition, and inversion work together can now be lifted into an extensional context with a quotient type.

\begin{implementation}
\isacommand{quotient{\isacharunderscore}type}\isamarkupfalse%
\ {\isacharprime}a\ prm\ =\ {\isachardoublequoteopen}{\isacharprime}a\ preprm{\isachardoublequoteclose}\ {\isacharslash}\ preprm{\isacharunderscore}ext\isanewline
%
\isatagproof
\isacommand{proof}\isamarkupfalse%
{\isacharparenleft}rule\ equivpI{\isacharparenright}\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}reflp\ preprm{\isacharunderscore}ext{\isachardoublequoteclose}\ \isacommand{using}\isamarkupfalse%
\ preprm{\isacharunderscore}ext{\isacharunderscore}reflp\isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}symp\ preprm{\isacharunderscore}ext{\isachardoublequoteclose}\ \isacommand{using}\isamarkupfalse%
\ preprm{\isacharunderscore}ext{\isacharunderscore}symp\isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}transp\ preprm{\isacharunderscore}ext{\isachardoublequoteclose}\ \isacommand{using}\isamarkupfalse%
\ preprm{\isacharunderscore}ext{\isacharunderscore}transp\isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\isacommand{qed}\isamarkupfalse%
\endisatagproof
\end{implementation}

The quotient-type construction produces a proof obligation to show that \(\equiv_p\) is an equivalence relation, which has already been shown.
There is now a tedious, but necessary task of lifting all definitions and lemmas (often easier to prove on the raw type) into the new equivalence.
For example, definitions are lifted like so:

\begin{implementation}
\isacommand{lift{\isacharunderscore}definition}\isamarkupfalse%
\ prm{\isacharunderscore}id\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ prm{\isachardoublequoteclose}\ {\isacharparenleft}{\isachardoublequoteopen}{\isasymepsilon}{\isachardoublequoteclose}{\isacharparenright}\ \isakeyword{is}\ preprm{\isacharunderscore}id%
\end{implementation}

and a lemma might be transferred from acting on the equivalence class to a concrete term like so:

\begin{implementation}
\isacommand{lemma}\isamarkupfalse%
\ prm{\isacharunderscore}apply{\isacharunderscore}injective{\isacharcolon}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}inj\ {\isacharparenleft}prm{\isacharunderscore}apply\ {\isasympi}{\isacharparenright}{\isachardoublequoteclose}\isanewline
%
\isadelimproof
%
\endisadelimproof
%
\isatagproof
\isacommand{by}\isamarkupfalse%
{\isacharparenleft}transfer,\ metis\ preprm{\isacharunderscore}apply{\isacharunderscore}injective{\isacharparenright}%
\endisatagproof
\end{implementation}

It's instructive to note at this point that the set of permutations over a base set \(S\), \(P_S\) form a group \(\wrap{P_S, \circ}\), with inverses being provided by the inverse operation, and \(\varepsilon\) as the identity element.

Some final operations did not need to be defined on pre-permutations, and could be defined directly on the quotiented type.

\begin{definition}
The image of a set \(S\) under a permutation \(\pi\), \(\pi \image S\), is the image of applying \(\pi\) on that set, \(\{\pi \dollar x\ |\ x \in S\}\).
\end{definition}

\begin{implementation}
\isacommand{definition}\isamarkupfalse%
\ prm{\isacharunderscore}set\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ prm\ {\isasymRightarrow}\ {\isacharprime}a\ set\ {\isasymRightarrow}\ {\isacharprime}a\ set{\isachardoublequoteclose}\ {\isacharparenleft}\isakeyword{where}\isanewline \ \ {\isachardoublequoteopen}prm{\isacharunderscore}set\ {\isasympi}\ S\ {\isasymequiv}\ image\ {\isacharparenleft}prm{\isacharunderscore}apply\ {\isasympi}{\isacharparenright}\ S{\isachardoublequoteclose}\isanewline
\end{implementation}

\section{Raw \(\lambda\)-terms}
Simple types and raw \(\lambda\)-terms are defined inductively with an Isabelle datatype, as described earlier.
I use natural numbers for a concrete variable type as there is a freshness implementation for them already, but any other variable that satisfies the freshness constraints can be used.
For instance, strings of characters are a possible variable type, but the set of booleans is not.

\begin{implementation}
\isacommand{type{\isacharunderscore}synonym}\isamarkupfalse%
\ tvar\ =\ nat\isanewline
\isanewline
\isacommand{datatype}\isamarkupfalse%
\ type\ =\isanewline
\ \ TVar\ tvar\isanewline
{\isacharbar}\ TArr\ type\ type\isanewline
\isanewline
\isacommand{datatype}\isamarkupfalse%
\ {\isacharprime}a\ ptrm\ =\isanewline
\ \ PVar\ {\isacharprime}a\isanewline
{\isacharbar}\ PApp\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
{\isacharbar}\ PFn\ {\isacharprime}a\ type\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
\end{implementation}

Defining the effect of permutations on pre-terms, \(\pi \bullet X\), is done recursively, since the applying the permutation commutes with the structure of the term until the base case (i.e. variables or the name in a binder).

\begin{implementation}
\isacommand{fun}\isamarkupfalse%
\ ptrm{\isacharunderscore}apply{\isacharunderscore}prm\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ prm\ {\isasymRightarrow}\ {\isacharprime}a\ ptrm\ {\isasymRightarrow}\ {\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
\ \ {\isachardoublequoteopen}ptrm{\isacharunderscore}apply{\isacharunderscore}prm\ {\isasympi}\ {\isacharparenleft}PVar\ x{\isacharparenright}\ =\ PVar\ {\isacharparenleft}{\isasympi}\ {\isachardollar}\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ {\isachardoublequoteopen}ptrm{\isacharunderscore}apply{\isacharunderscore}prm\ {\isasympi}\ {\isacharparenleft}PApp\ A\ B{\isacharparenright}\ =\ PApp\isanewline
\ \ \ \ {\isacharparenleft}ptrm{\isacharunderscore}apply{\isacharunderscore}prm\ {\isasympi}\ A{\isacharparenright}\isanewline
\ \ \ \ {\isacharparenleft}ptrm{\isacharunderscore}apply{\isacharunderscore}prm\ {\isasympi}\ B{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ {\isachardoublequoteopen}ptrm{\isacharunderscore}apply{\isacharunderscore}prm\ {\isasympi}\ {\isacharparenleft}PFn\ x\ T\ A{\isacharparenright}\ =\ PFn\ {\isacharparenleft}{\isasympi}\ {\isachardollar}\ x{\isacharparenright}\ T\ {\isacharparenleft}ptrm{\isacharunderscore}apply{\isacharunderscore}prm\ {\isasympi}\ A{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

I then can re-define a number of lemmas about the application of permutations in the context of pre-terms by transcribing them.
For example, compare the following with the corresponding lemmas about application of permutations on names.

\begin{implementation}
\isacommand{lemma}\isamarkupfalse%
\ ptrm{\isacharunderscore}prm{\isacharunderscore}apply{\isacharunderscore}id{\isacharcolon}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isasymepsilon}\ {\isasymbullet}\ X\ =\ X{\isachardoublequoteclose}\isanewline
\isatagproof
\isacommand{by}\isamarkupfalse%
{\isacharparenleft}induction\ X,\ simp{\isacharunderscore}all\ add{\isacharcolon}\ prm{\isacharunderscore}apply{\isacharunderscore}id{\isacharparenright}%
\endisatagproof
\isanewline
\isanewline
\isacommand{lemma}\isamarkupfalse%
\ ptrm{\isacharunderscore}prm{\isacharunderscore}apply{\isacharunderscore}compose{\isacharcolon}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isasympi}\ {\isasymbullet}\ {\isasymsigma}\ {\isasymbullet}\ X\ =\ {\isacharparenleft}{\isasympi}\ {\isasymdiamondop}\ {\isasymsigma}{\isacharparenright}\ {\isasymbullet}\ X{\isachardoublequoteclose}\isanewline
\isatagproof
\isacommand{by}\isamarkupfalse%
{\isacharparenleft}induction\ X,\ simp{\isacharunderscore}all\ add{\isacharcolon}\ prm{\isacharunderscore}apply{\isacharunderscore}composition{\isacharparenright}%
\endisatagproof
\end{implementation}

Free variables of a term can also be defined recursively.

\begin{implementation}
\isacommand{fun}\isamarkupfalse%
\ ptrm{\isacharunderscore}fvs\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm\ {\isasymRightarrow}\ {\isacharprime}a\ set{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}ptrm{\isacharunderscore}fvs\ {\isacharparenleft}PVar\ x{\isacharparenright}\ {\isacharequal}\ {\isacharbraceleft}x{\isacharbraceright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ {\isachardoublequoteopen}ptrm{\isacharunderscore}fvs\ {\isacharparenleft}PApp\ A\ B{\isacharparenright}\ {\isacharequal}\ ptrm{\isacharunderscore}fvs\ A\ {\isasymunion}\ ptrm{\isacharunderscore}fvs\ B{\isachardoublequoteclose}\isanewline
{\isacharbar}\ {\isachardoublequoteopen}ptrm{\isacharunderscore}fvs\ {\isacharparenleft}PFn\ x\ {\isacharunderscore}\ A{\isacharparenright}\ {\isacharequal}\ ptrm{\isacharunderscore}fvs\ A\ {\isacharminus}\ {\isacharbraceleft}x{\isacharbraceright}{\isachardoublequoteclose}\isanewline
\end{implementation}

In later lemmas, a given set of names frequently has to be shown to be finite, so that a fresh name can be generated with respect to them.
To aid this, show that the free variables of a term are always finite.
\begin{lemma}
For any \(X\), the free variables of \(X\) form a finite set.
\end{lemma}
\begin{proof}
By induction on \(X\).
\end{proof}

Also, the free-variables operation can be shown to be equivariant, the first case of this property in the project.
\begin{lemma}
For any \(X\) and \(\pi\), the free variables of \(\pi \bullet X\) are the image of \(\pi\) in the free variables of \(X\).
\end{lemma}
\begin{proof}
By induction on \(X\).
\begin{enumerate}
\item
In the case of variables, note that \(\pi \bullet x = \pi \dollar x\).
Then the proposition follows directly.
\item
Assume that \(\fvs\wrap{\pi \bullet A} = \pi \image \fvs(A)\), and similarly for \(B\).
Then the lemma holds for \(\wrap{A\ B}\):
\begin{align*}
\fvs\wrap{\pi \bullet \wrap{A\ B}}
&= \fvs\wrap{\wrap{\pi \bullet A}\ \wrap{\pi \bullet B}}\\
&= \fvs\wrap{\pi \bullet A} \cup \fvs\wrap{\pi \bullet A}\\
&= \pi \image \fvs(A) \cup \pi \image \fvs(B)\\
&= \pi \image \wrap{\fvs(A) \cup \fvs(B)}\\
&= \pi \image \fvs\wrap{A\ B}
\end{align*}
\item
Assume that \(\fvs\wrap{\pi \bullet A} = \pi \image \fvs(A)\).
Then finish the lemma similarly:
\begin{align*}
\fvs\wrap{\pi \bullet \lambda \wrap{x:T}.A} 
&= \fvs\wrap{\lambda \wrap{\pi \dollar x : T}. \wrap{\pi \bullet A}}\\
&= \fvs\wrap{\pi \bullet A} - \wrap{\pi \dollar x}\\
&= \pi \image \fvs(A) - \wrap{\pi \dollar x}\\
&= \pi \image \wrap{\fvs(A) - x}\\
&= \pi \image \wrap{\fvs\wrap{\lambda (x:T).A}}
\end{align*}
\end{enumerate}
\end{proof}

Isabelle also provides a function called \texttt{size} with every datatype to determine the number of nodes contained within a given instance of the datatype --- this corresponds to the definition of term size \(|M|\) described earlier.
To use the size of a term in later arguments (e.g. for induction on the size of said term), it is useful to show that \(|\pi \bullet M| = |M|\), i.e. that permutation does not change the size of a term.

\begin{lemma}
The size of a pre-term \(X\) is the same as the size of \(X\) under a permutation, \(\pi \bullet X\).
\end{lemma}
\begin{proof}
By induction on \(X\), then by definition of permutation application.
\end{proof}

\subsection{\(\alpha\)-equivalence}
Isabelle provides built-in support for inductive definitions, so reproducing the nominal definition of \(\alpha\)-equivalence introduced in the Preparation chapter is straightforward.
I used a slightly different formulation in which there are two cases for functions: one where the swapping variables are the same, and one when they are not.
This is equivalent, but makes for a shorter proof script.

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\isanewline
\ \ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm\ {\isasymRightarrow}\ {\isacharprime}a\ ptrm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{where}\isanewline
\ \ var{\isacharcolon}\ {\isachardoublequoteopen}{\isacharparenleft}PVar\ x{\isacharparenright}\ {\isasymapprox}\ {\isacharparenleft}PVar\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ app{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isasymapprox}\ B{\isacharsemicolon}\ C\ {\isasymapprox}\ D{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}PApp\ A\ C{\isacharparenright}\ {\isasymapprox}\ {\isacharparenleft}PApp\ B\ D{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fn{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}A\ {\isasymapprox}\ B\ {\isasymLongrightarrow}\ {\isacharparenleft}PFn\ x\ T\ A{\isacharparenright}\ {\isasymapprox}\ {\isacharparenleft}PFn\ x\ T\ B{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fn{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}a\ {\isasymnoteq}\ b{\isacharsemicolon}\ A\ {\isasymapprox}\ {\isacharbrackleft}a\ {\isasymleftrightarrow}\ b{\isacharbrackright}\ {\isasymbullet}\ B{\isacharsemicolon}\ a\ {\isasymnotin}\ ptrm{\isacharunderscore}fvs\ B{\isasymrbrakk}\isanewline
\ \ \ \ \ \ \ \ {\isasymLongrightarrow}\ {\isacharparenleft}PFn\ a\ T\ A{\isacharparenright}\ {\isasymapprox}\ {\isacharparenleft}PFn\ b\ T\ B{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

However, it does not provide eliminators by default, and these must be added manually using a separate command.
Eliminators provide reasoning to ``go backwards'' from an inductive predicate, and see what conditions might have caused it to hold.
For example, if \(\wrap{A\ C} \sim \wrap{B\ D}\), the only conclusion we can draw from the definition of \(\sim\) is that \(A \sim B\) and \(C \sim D\).

\begin{implementation}
\isacommand{inductive{\isacharunderscore}cases}\isamarkupfalse%
\ varE{\isacharcolon}\ \ {\isachardoublequoteopen}PVar\ x\ {\isasymapprox}\ Y{\isachardoublequoteclose}\isanewline
\isacommand{inductive{\isacharunderscore}cases}\isamarkupfalse%
\ appE{\isacharcolon}\ \ {\isachardoublequoteopen}PApp\ A\ B\ {\isasymapprox}\ Y{\isachardoublequoteclose}\isanewline
\isacommand{inductive{\isacharunderscore}cases}\isamarkupfalse%
\ fnE{\isacharcolon}\ \ \ {\isachardoublequoteopen}PFn\ x\ T\ A\ {\isasymapprox}\ Y{\isachardoublequoteclose}\isanewline
\end{implementation}

These provide this style of reasoning, bound to the labels as a theorem.
For instance \emph{varE} is effectively

\begin{implementation}
\isacommand{lemma}\isamarkupfalse%
\ varE\isanewline
\ \ \isakeyword{fixes}\ P\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}PVar x\ {\isasymapprox}\ Y{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}Y = PVar x {\isasymLongrightarrow} P{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}P{\isachardoublequoteclose}\isanewline
\isakeyword{proof}\isanewline
\ \ \ldots\isanewline
\isakeyword{qed}\isanewline
\end{implementation}

A good test of the definition of this relation is to show that free variables and permutation application are preserved under it, a fundamental property of \(\alpha\)-equivalence.

\begin{lemma}
Assume \(X \sim Y\).
Then \(\fvs(X) = \fvs(Y)\).
\end{lemma}
\begin{proof}
By induction on the derivation of \(X \sim Y\).
\emph{var}, \emph{app}, and \emph{fn1} are easy.

For \emph{fn2}, assume:
\begin{itemize}
\item
\(a \neq b\)
\item
\(A \sim [a \swap b] \bullet B\)
\item
\(a \notin \fvs(B)\)
\item
the induction hypothesis, \(\fvs(A) = \fvs\wrap{[a \swap b] \bullet B}\)
\end{itemize}
Then, try and show \(\fvs\wrap{\lambda (a:T).A} = \fvs\wrap{\lambda (b:T).B}\).
\begin{align*}
\fvs\wrap{\lambda (a:T).A}
&= \fvs(A) - a\\
&= \fvs\wrap{[a \swap b] \bullet B} - a\\
&= \wrap{[a \swap b] \image \fvs(B)} - a\\
\end{align*}
Now the proof is stuck --- the proof will follow from arriving at the term \(\fvs(B) - b\), but simplifying will not arrive there.
To fix this, consider whether \(b\) is in the free variables of \(B\).
If it is, then \([a \swap b] \image \fvs(B) = \fvs(B) - {b} \cup {a}\), since \(a \notin \fvs(B)\), so
\begin{align*}
\wrap{[a \swap b] \image \fvs(B)} - a
&= \fvs(B) - {b} \cup {a} - a\\
&= \fvs(B) - b
\end{align*}
If it is not, then \([a \swap b]\) has no effect, so
\begin{align*}
\wrap{[a \swap b] \image \fvs(B)} - a
&= \fvs(B) - a\\
&= \fvs(B) = \fvs(B) - b
\end{align*}
Now
\begin{align*}
\fvs\wrap{\lambda (a:T).A}
&= \fvs(B) - b\\
&= \fvs\wrap{\lambda (b:T).B}
\end{align*}
\end{proof}

\begin{lemma}
\label{lemma:prm-equivalent}
Assume \(X \sim Y\).
Then \(\pi \bullet X \sim \pi \bullet Y\).
This shows that \(\alpha\)-equivalence is respected by changing variable names, as long as it is done consistently.
\end{lemma}
\begin{proof}
By induction on the derivation of \(X \sim Y\).
Again \emph{var}, \emph{app}, and \emph{fn1} turn out to be easy.
For \emph{fn2}, assume as usual that \(a \neq b\), \(a \notin \fvs(B)\), and the induction hypothesis \(\pi \bullet A \sim \pi \bullet [a \swap b] \bullet B\).
Then, deduce from these the preconditions for \(\lambda (\pi \dollar a:T). \pi \bullet A \sim \lambda (\pi \dollar b:T). \pi \bullet B\), namely that
\begin{itemize}
\item
\(\pi \bullet a \neq \pi \bullet b\)
\item
\(\pi \dollar a \notin \fvs\wrap{\pi \bullet B}\)
\item
\(\pi \bullet A \sim [\pi \dollar a \swap \pi \dollar b] \bullet \pi \bullet B\)
\end{itemize}
Finally, see that both sides of the equivalence can be simplified to produce the result.
\end{proof}

Now I show that \(\sim\) is an equivalence relation.
Some simple but specific results are needed first, which are presented informally:

\begin{lemma}
\label{lemma:transfer-swapping}
The statement \([a \swap b] \bullet X \sim Y\) is equivalent to the statement \(X \sim [a \swap b] \bullet Y\).
\end{lemma}
\begin{proof}
This can be shown in both directions by permuting both sides by \([a \swap b]\) again using Lemma \ref{lemma:prm-equivalent}, then using the fact that \([a \swap b] \diamond [a \swap b] = \varepsilon\).
\end{proof}

\begin{lemma}
\label{lemma:transfer-freshness}
If \(a \notin \fvs(B)\), and \(A \sim [a \swap b] \bullet B\), then \(b \notin \fvs(A)\).
\end{lemma}
\begin{proof}
By a similar argument.
\end{proof}

These are now used to argue the conditions of being an equivalence relation, namely reflexivity, symmetry, and transitivity.

\begin{lemma}
\(\sim\) is reflexive: that is, for all terms \(X\), \(X \sim X\).
\end{lemma}
\begin{proof}
By induction on \(X\).
\end{proof}

\begin{lemma}
\(\sim\) is symmetric, so for all terms \(X\), \(Y\), \(X \sim Y \Longrightarrow Y \sim X\).
\end{lemma}
\begin{proof}
By induction on the derivation of \(X \sim Y\).
As usual, \emph{fn2} is the difficult case.
It is given from the induction process that \(a \neq b\), \(A \sim [a \swap b] \bullet B\), \(a \notin \fvs(B)\), and the inductive hypothesis, \([a \swap b] \bullet B \sim A\).
From these and Lemmas \ref{lemma:transfer-swapping} and \ref{lemma:transfer-freshness}, deduce that \(b \neq a\), \(B \sim [b \swap a] \bullet A\), and \(b \notin \fvs(A)\).
Then note that these are the conditions required to show \(\lambda (b:T).B \sim \lambda (a:T).A\), which is the required result.
\end{proof}

\begin{lemma}
\(\sim\) is transitive.
If \(X \sim Y\) and \(Y \sim Z\), then \(X \sim Z\).
\end{lemma}
\begin{proof}
By induction on the size of \(X\), then by cases on \(X\).
This generates the inductive hypothesis
\[
\forall K Y Z. \wrap{|K| < |X|, K \sim Y, Y \sim Z} \Longrightarrow K \sim Z
\]
If \(X\) is a variable, the result follows by deducing that \(Y\) and \(Z\) must also be variables (using the eliminators defined earlier), and that they must all be the same variable.
If \(X\) is instead an application, the inductive hypothesis can be used to show that both components of the application in \(X\) and \(Z\) are equivalent, and hence that \(X \sim Z\) by definition of \(\sim\).

Finally, if \(X\) is an abstraction, there are four cases to consider, depending on whether \emph{fn1} or \emph{fn2} is used to get from \(X\) to \(Y\), and again from \(Y\) to \(Z\).
The difficult case is when both relations are produced by \emph{fn2}.
This case can be further broken down when \(X\) and \(Z\) use the same variable in their binder --- suppose \(X = \lambda (x:T).A\), \(Y = \lambda (y:T).B\), and \(Z = \lambda (z:T). C\), then either \(x = z\) or \(x \neq z\).
If \(x = z\), then \(A \sim C\); since \(A \sim [x \swap y] \bullet B\) and \(B \sim [y \swap x] \bullet C\), \(A \sim [x \swap y] \bullet [y \swap x] \bullet C\), so \(A \sim C\) since the swappings cancel out.

However, if \(x \neq z\), \(X \sim Z\) has to be shown by \emph{fn2}.
Since both derivations were by \emph{fn2}, \(A \sim [x \swap y] \bullet [y \swap z] \bullet C\), but since \(x\), \(y\), and \(z\) are all now distinct it is possible to show (by definition of permutations) that \([x \swap y] \diamond [y \swap z] = [x \swap z]\), so \(A \sim [x \swap z] \bullet C\).
Also, \(x \notin \fvs(C)\) holds by noting that \(x \notin \fvs([y \swap z] \bullet C)\), then considering if \(z\) is in the free variables of \(C\).
If it is, then \(x \notin \fvs(C)\), since \(x \neq y \neq z\) and hence swapping \(z\) for \(y\) has no effect on whether \(x\) is in the free variables of the term or not.
If it is not, then the swapping has no effect, so \(x \notin \fvs(C)\) trivially.

Concluding, \(x \neq z\), \(A \sim [x \swap z] \bullet C\), and \(x \notin \fvs(C)\), so it follows that \(\lambda (x:T).A \sim \lambda (z:T).C\).
\end{proof}

\begin{theorem}
\(\sim\) is an equivalence relation.
\end{theorem}
\begin{proof}
Since \(\sim\) is reflexive, symmetric, and transitive, it is an equivalence relation.
\end{proof}

\subsection{Type Inference Algorithm}
The last task that needs to be done on the pre-terms is to implement a type inference algorithm on the concrete syntax, which can then be lifted to terms.

The algorithm is implemented as follows, which typing contexts modelled as a partial function from names to terms.

\begin{implementation}
\isacommand{type{\isacharunderscore}synonym}\isamarkupfalse%
\ {\isacharprime}a\ typing{\isacharunderscore}ctx\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharprime}a\ {\isasymrightharpoonup}\ type{\isachardoublequoteclose}\isanewline
\isanewline
\isacommand{fun}\isamarkupfalse%
\ ptrm{\isacharunderscore}infer{\isacharunderscore}type\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ typing{\isacharunderscore}ctx\ {\isasymRightarrow}\ {\isacharprime}a\ ptrm\ {\isasymRightarrow}\ type\ option{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}ptrm{\isacharunderscore}infer{\isacharunderscore}type\ {\isasymGamma}\ {\isacharparenleft}PVar\ x{\isacharparenright}\ {\isacharequal}\ {\isasymGamma}\ x{\isachardoublequoteclose}\isanewline
{\isacharbar}\ {\isachardoublequoteopen}ptrm{\isacharunderscore}infer{\isacharunderscore}type\ {\isasymGamma}\ {\isacharparenleft}PApp\ A\ B{\isacharparenright}\ {\isacharequal}\isanewline
\ \ \ \ {\isacharparenleft}case\ {\isacharparenleft}ptrm{\isacharunderscore}infer{\isacharunderscore}type\ {\isasymGamma}\ A{\isacharcomma}\ ptrm{\isacharunderscore}infer{\isacharunderscore}type\ {\isasymGamma}\ B{\isacharparenright}\ of\isanewline
\ \ \ \ \ \ \ {\isacharparenleft}Some\ {\isacharparenleft}TArr\ {\isasymtau}\ {\isasymsigma}{\isacharparenright}{\isacharcomma}\ Some\ {\isasymtau}{\isacharprime}{\isacharparenright}\ {\isasymRightarrow}\ {\isacharparenleft}if\ {\isasymtau}\ {\isacharequal}\ {\isasymtau}{\isacharprime}\ then\ Some\ {\isasymsigma}\ else\ None{\isacharparenright}\isanewline
\ \ \ \ \ {\isacharbar}\ {\isacharunderscore}\ {\isasymRightarrow}\ None\isanewline
\ \ \ {\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ {\isachardoublequoteopen}ptrm{\isacharunderscore}infer{\isacharunderscore}type\ {\isasymGamma}\ {\isacharparenleft}PFn\ x\ {\isasymtau}\ A{\isacharparenright}\ {\isacharequal}\ {\isacharparenleft}case\ ptrm{\isacharunderscore}infer{\isacharunderscore}type\ {\isacharparenleft}{\isasymGamma}{\isacharparenleft}x\ {\isasymmapsto}\ {\isasymtau}{\isacharparenright}{\isacharparenright}\ A\ of\isanewline
\ \ \ \ \ Some\ {\isasymsigma}\ {\isasymRightarrow}\ Some\ {\isacharparenleft}TArr\ {\isasymtau}\ {\isasymsigma}{\isacharparenright}\isanewline
\ \ \ {\isacharbar}\ None\ {\isasymRightarrow}\ None\isanewline
\ \ \ {\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

Before this definition can be lifted across equivalence classes, it is required to show that it is invariant under \(\alpha\)-equivalence.
This can be done with the help of a lemma about swapping names in a typing context.

\begin{lemma}
\label{lemma:infer-typing-swap}
Assume two names \(a\) and \(b\) are distinct, and \(b \notin \fvs(X)\).
Then
\[
\infertype\wrap{\Gamma\{a \mapsto \tau\}, X} = \infertype\wrap{\Gamma\{b \mapsto \tau\}, [a \swap b] \bullet X}
\]
\end{lemma}
\begin{proof}
By induction on the structure of \(X\).
\end{proof}

\begin{theorem}
The inference algorithm is invariant under equivalence.
If \(X \sim Y\), then for any context \(\Gamma\),
\[
\infertype\wrap{\Gamma, X} = \infertype\wrap{\Gamma, Y}
\]
\end{theorem}
\begin{proof}
By induction on the derivation of \(X \sim Y\).
All cases other than \emph{fn2} follow immediately by definition.
For \emph{fn2}, use the definition of the type inference algorithm and Lemma \ref{lemma:infer-typing-swap} to show that the function bodies have the same type \(\sigma\), then note that both \(X\) and \(Y\) then have inferred type \(\tau \to \sigma\).
\end{proof}

\section{\(\lambda\)-terms with \(\alpha\)-equivalence}
As before with permutations, pre-terms can now be lifted to terms using the quotient-type machinery.

\begin{implementation}
\isacommand{quotient{\isacharunderscore}type}\isamarkupfalse%
\ {\isacharprime}a\ trm\ {\isacharequal}\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\ {\isacharslash}\ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv\isanewline
%
\isadelimproof
%
\endisadelimproof
%
\isatagproof
\isacommand{proof}\isamarkupfalse%
{\isacharparenleft}rule\ equivpI{\isacharparenright}\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}reflp\ \ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv{\isachardoublequoteclose}\ \isacommand{using}\isamarkupfalse%
\ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv{\isacharunderscore}reflp\isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}symp\ \ \ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv{\isachardoublequoteclose}\ \isacommand{using}\isamarkupfalse%
\ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv{\isacharunderscore}symp\isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\ \ \isacommand{show}\isamarkupfalse%
\ {\isachardoublequoteopen}transp\ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv{\isachardoublequoteclose}\ \isacommand{using}\isamarkupfalse%
\ ptrm{\isacharunderscore}alpha{\isacharunderscore}equiv{\isacharunderscore}transp\isacommand{{\isachardot}}\isamarkupfalse%
\isanewline
\isacommand{qed}\isamarkupfalse%
%
\endisatagproof
\end{implementation}

Again, all the definitions have to be lifted as well, but there is some extra boilerplate now, as equality rules don't necessarily hold.
First, every lifted datatype constructor has to be shown to be not equal to every other datatype constructor, of which the following is an indicative example.

\begin{implementation}
\isacommand{lemma}\isamarkupfalse%
\ var{\isacharunderscore}not{\isacharunderscore}app{\isacharcolon}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}Var\ x\ {\isasymnoteq}\ App\ A\ B{\isachardoublequoteclose}\isanewline
%
\isadelimproof
%
\endisadelimproof
%
\isatagproof
\isacommand{proof}\isamarkupfalse%
{\isacharparenleft}transfer{\isacharparenright}\isanewline
\ \ \ldots\isanewline
\isacommand{qed}\isamarkupfalse%
%
\endisatagproof
\end{implementation}

Then, the ``obvious'' conclusions from equality don't necessarily hold either, and must be shown manually.
For example, suppose \(\wrap{A\ B} = \wrap{C\ D}\).
You can conclude that \(A = C\) and \(B = D\) from this, but with the quotient type Isabelle cannot infer this and it has to be shown manually.

Isabelle does not generate an induction principle for the new terms automatically, but it is possible to produce one by deferring to the concrete-syntax induction principle.

\begin{lemma}
Suppose \(P\) is a unary predicate on terms, suppose also that for all variables \(x\), \(P(x)\) holds, that if \(P(A)\) and \(P(B)\) hold, then \(P\wrap{A\ B}\) also holds, and finally that if \(P(A)\) holds, then \(P\wrap{\lambda (x:T). A}\) also holds.
Then for any term \(M\), \(P(M)\).
\end{lemma}
\begin{proof}
Transfer these hypotheses to the level of pre-terms, then show that for any pre-term \(X\), \(P\wrap{\textrm{Abs}(X)}\), by using the pre-term induction principle.
The result then follows from lifting this result back up to the level of terms.
\end{proof}

Similar principles can also be produced for proof by cases and proof by induction on the size of a term.
Being able to prove and use different induction principles also allows for proof by \emph{strong} induction.
This is a useful principle to have, as assuming that \(x\) is fresh in a set makes many proofs simpler and shorter.

\begin{lemma}
Suppose now that \(P\) is a \emph{binary} predicate on pairs consisting of a set of names and a term.
The term is the object of induction, and \(S\) is a set of names to avoid when discussing binders.
Suppose that
\begin{enumerate}
\item
\(S\) is a finite set of names.
\item
\(P\wrap{S, x}\), for any variable \(x\).
\item
If \(P\wrap{S, A}\) and \(P\wrap{S, B}\), then \(P\wrap{S, \wrap{A\ B}}\).
\item
If \(x \notin S\) and \(P\wrap{S, A}\), then \(P\wrap{S, \wrap{\lambda (x:T). A}}\).
\end{enumerate}
Now for any term \(M\), \(P\wrap{S, M}\).
\end{lemma}
\begin{proof}
First, show a more general property: that for any permutation \(\pi\), \(P\wrap{S, \pi \cdot M}\).
This is argued by induction on \(M\), using the simple induction rule proved earlier.
The variable and application cases are by analogy with the simple induction, but the function binder needs special attention.

In the binding case, assume that \(P\wrap{S, \pi \cdot A}\) for any \(\pi\), and show that \(P\wrap{S, \pi \cdot \lambda (x:T).A}\).
To prove this, produce a new variable \(y\) (using the freshness implementation) that is fresh with respect to the union of \(S\), the free variables of \(\pi \cdot A\), and \(\pi \dollar z\).
Now for any \(B\), if \(P\wrap{S, B}\), then \(P\wrap{S, \lambda (y:T).B}\), using the assumptions --- in particular, \(P\wrap{S, \lambda (y:T). \wrap{[y \swap \pi \dollar x] \diamond \pi} \cdot A}\).

However, by using the \emph{fn2} rule, it can be shown that
\begin{align*}
\lambda (y:T). \wrap{[y \swap \pi \dollar x] \diamond \pi} \cdot A
&= \lambda (\pi \dollar x:T). \pi \cdot A\\
&= \pi \cdot \lambda (x:T). A
\end{align*}
And so \(P\wrap{S, \pi \cdot \lambda (x:T).A}\) holds for any \(\pi\).

Now that the stronger result is established, the original result can be shown by setting \(\pi = \varepsilon\).
\end{proof}

Further induction principles can be produced by combining the strong induction principle with proof by cases (``strong cases'') and proof by induction on the size of a term (``strong depth induction'').

\subsection{Typing Judgements}
An explicit inductively-defined typing relation is used to ensure that the type inference algorithm is correct (or at least respects the typing judgements as written).
Additionally, it is easier to argue that inductive definitions respect certain properties (e.g. the subject reduction property), then to show that the algorithm is sound and complete with respect to the judgements, than it is to argue directly about the algorithm.

The judgements presented earlier are encoded in Isabelle as follows:

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\ typing\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ typing{\isacharunderscore}ctx\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ type\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\  \isakeyword{where}\isanewline
\ \ tvar{\isacharcolon}\ \ {\isachardoublequoteopen}{\isasymGamma}\ x\ {\isacharequal}\ Some\ {\isasymtau}\ {\isasymLongrightarrow}\ {\isasymGamma}\ {\isasymturnstile}\ Var\ x\ {\isacharcolon}\ {\isasymtau}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ tapp{\isacharcolon}\ \ {\isachardoublequoteopen}{\isasymlbrakk}{\isasymGamma}\ {\isasymturnstile}\ f\ {\isacharcolon}\ {\isacharparenleft}TArr\ {\isasymtau}\ {\isasymsigma}{\isacharparenright}{\isacharsemicolon}\ {\isasymGamma}\ {\isasymturnstile}\ x\ {\isacharcolon}\ {\isasymtau}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isasymGamma}\ {\isasymturnstile}\ App\ f\ x\ {\isacharcolon}\ {\isasymsigma}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ tfn{\isacharcolon}\ \ \ {\isachardoublequoteopen}{\isasymGamma}{\isacharparenleft}x\ {\isasymmapsto}\ {\isasymtau}{\isacharparenright}\ {\isasymturnstile}\ A\ {\isacharcolon}\ {\isasymsigma}\ {\isasymLongrightarrow}\ {\isasymGamma}\ {\isasymturnstile}\ Fn\ x\ {\isasymtau}\ A\ {\isacharcolon}\ {\isacharparenleft}TArr\ {\isasymtau}\ {\isasymsigma}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

The usual eliminators then need to be proved manually, as the quotient type adds a layer of complexity that Isabelle's usual inductive-cases feature cannot currently deal with.
For example,

\begin{implementation}
\isacommand{lemma}\isamarkupfalse%
\ typing{\isacharunderscore}appE{\isacharcolon}\isanewline
\ \ \isakeyword{assumes}\ {\isachardoublequoteopen}{\isasymGamma}\ {\isasymturnstile}\ App\ A\ B\ {\isacharcolon}\ {\isasymsigma}{\isachardoublequoteclose}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isasymexists}{\isasymtau}{\isachardot}\ {\isacharparenleft}{\isasymGamma}\ {\isasymturnstile}\ A\ {\isacharcolon}\ {\isacharparenleft}TArr\ {\isasymtau}\ {\isasymsigma}{\isacharparenright}{\isacharparenright}\ {\isasymand}\ {\isacharparenleft}{\isasymGamma}\ {\isasymturnstile}\ B\ {\isacharcolon}\ {\isasymtau}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

provides a mechanism for reasoning about the typing judgement of an application in reverse.
With these eliminators, the first of several properties about the type system can be shown: weakening.

\begin{theorem}
Assume that \(\Gamma \vdash M : \tau\), and pick \(y\) such that \(y \notin \fvs(M)\).
Then
\[\Gamma\{y \mapsto \sigma\} \vdash M : \tau\]
for any \(\sigma\) --- that is, weakening the typing context with any other variable derives the same type, providing that the variable is fresh.
\end{theorem}
\begin{proof}
By induction on the derivation of the typing induction.
\emph{tvar} and \emph{tapp} turn out to be easy, but the presence of a binder in \emph{tfn} complicates matters.
From assumption, we have that \(y \notin \fvs\wrap{\lambda (x:\tau). A}\), so either \(y = x\) or \(y \notin \fvs(A)\).
In the first case, adding the \(x \mapsto \tau\) to the context simply overwrites the weakened context.
For the second, \(y \notin \fvs(A)\) can be combined with the induction hypothesis to show the result.
\end{proof}

\subsection{Substitution and \(\beta\)-Reduction}
Most of the properties I show about the type system of the calculus require an implementation of \(\beta\)-reduction, which itself requires substitution to be defined first.
I define a substitution relation inductively, then show that the relation is a function, so that \(\beta\)-reduction can be defined in terms of it.
While it is possible to define substitution as a function directly, it has to be done on pre-terms, then lifted to the quotiented terms, as Isabelle's function package does not support defining functions on equivalence classes.

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\ substitutes\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ var{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}x\ {\isacharequal}\ y\ {\isasymLongrightarrow}\ substitutes\ {\isacharparenleft}Var\ x{\isacharparenright}\ y\ M\ M{\isachardoublequoteclose}\isanewline
{\isacharbar}\ var{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}x\ {\isasymnoteq}\ y\ {\isasymLongrightarrow}\ substitutes\ {\isacharparenleft}Var\ x{\isacharparenright}\ y\ M\ {\isacharparenleft}Var\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ app{\isacharcolon}\ \ {\isachardoublequoteopen}{\isasymlbrakk}substitutes\ A\ x\ M\ A{\isacharprime}{\isacharsemicolon}\ substitutes\ B\ x\ M\ B{\isacharprime}{\isasymrbrakk}\isanewline
\ \ \ \ \ \ {\isasymLongrightarrow}\ substitutes\ {\isacharparenleft}App\ A\ B{\isacharparenright}\ x\ M\ {\isacharparenleft}App\ A{\isacharprime}\ B{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fn{\isacharcolon}\ \ \ {\isachardoublequoteopen}{\isasymlbrakk}x\ {\isasymnoteq}\ y{\isacharsemicolon}\ y\ {\isasymnotin}\ fvs\ M{\isacharsemicolon}\ substitutes\ A\ x\ M\ A{\isacharprime}{\isasymrbrakk}\isanewline
\ \ \ \ \ \ substitutes\ {\isacharparenleft}Fn\ y\ T\ A{\isacharparenright}\ x\ M\ {\isacharparenleft}Fn\ y\ T\ A{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

The usual eliminators follow.
For a relation \(R\) to a be a function, it has to be both \emph{total} --- that is, for every \(a\), there is a \(b\), such that \(\wrap{a, b} \in R\) --- and \emph{single-valued}, so there is only one \(b\) for any \(a\).

\begin{lemma}
\label{lemma:substitution-total}
The substitution relation is total: for any term \(A\), there is an \(A'\) which is the substitution of \(x\) for \(M\) in \(A\).
\end{lemma}
\begin{proof}
By strong induction on \(A\), avoiding both \(x\) and the free variables of \(M\).
For the variable case, consider whether the variable is equal to \(x\) or not, and use either the \emph{var1} or \emph{var2} rules accordingly.
Applications follow straightforwardly from the induction hypotheses.
Finally, for functions \(\lambda (y:T). B\), note that \(y \neq x\) and \(y \notin \fvs(M)\), by the strong induction hypothesis.
Hence the \emph{fn} rule applies.
\end{proof}

\begin{lemma}
\label{lemma:substitution-unique}
The substitution relation is unique: if \(B\) and \(C\) are both substitutions of \(x\) for \(M\) in \(A\), then \(B = C\).
\end{lemma}
\begin{proof}
Again by strong induction on \(A\), avoiding \(x\) and \(\fvs(M)\).
Each case can be proved by using the appropriate eliminator.
\end{proof}

\begin{lemma}
Substitution is a function.
\end{lemma}
\begin{proof}
Using Lemmas \ref{lemma:substitution-unique} and \ref{lemma:substitution-total}, substitution is a function by definition.
\end{proof}

It is possible to define a function within Isabelle that finds the unique term that a substitution results in.
This is done using the definition description operator, which Isabelle calls ``THE''.
Then, a series of simplification lemmas can be used to make this definition useful, which all use this result to argue that the substitution has exactly one result.
While substitution is clearly an executable algorithm, this definition is not exexecutable by Isabelle as there is no direct definition it can follow for it.
It may be possible to use Isabelle's code transformation with added user-defined properties to allow an extracted implementation (discussed later), but this is left as an extension.

\begin{implementation}
\isacommand{definition}\isamarkupfalse%
\ subst\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ trm{\isachardoublequoteclose}\ {\isacharparenleft}{\isachardoublequoteopen}{\isacharunderscore}{\isacharbrackleft}{\isacharunderscore}\ {\isacharcolon}{\isacharcolon}{\isacharequal}\ {\isacharunderscore}{\isacharbrackright}{\isachardoublequoteclose}{\isacharparenright}\ \isakeyword{where}\isanewline
\ \ {\isachardoublequoteopen}subst\ A\ x\ M\ {\isasymequiv}\ {\isacharparenleft}THE\ X{\isachardot}\ substitutes\ A\ x\ M\ X{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

For an example of a simplification lemma for this function, consider the result of substituting \(M\) for \(x\) in the term \(x\).

\begin{implementation}
\isacommand{lemma}\isamarkupfalse%
\ subst{\isacharunderscore}simp{\isacharunderscore}var{\isadigit{1}}{\isacharcolon}\isanewline
\ \ \isakeyword{shows}\ {\isachardoublequoteopen}{\isacharparenleft}Var\ x{\isacharparenright}{\isacharbrackleft}x\ {\isacharcolon}{\isacharcolon}{\isacharequal}\ M{\isacharbrackright}\ {\isacharequal}\ M{\isachardoublequoteclose}\isanewline
\isatagproof
\isacommand{unfolding}\isamarkupfalse%
\ subst{\isacharunderscore}def\ \isacommand{by}\isamarkupfalse%
{\isacharparenleft}\isanewline
\ \ rule{\isacharcomma}\isanewline
\ \ metis\ substitutes{\isachardot}var{\isadigit{1}}{\isacharcomma}\isanewline
\ \ metis\ substitutes{\isacharunderscore}function\ substitutes{\isachardot}var{\isadigit{1}}\isanewline
{\isacharparenright}%
\end{implementation}

At this point, I can showcase the strength of the strong induction principle (and hence the whole nominal approach) by showing \emph{Barendregt's substitution lemma}~\cite{lambda-overview}, which produces a method of re-writing substitutions in a different order.

\begin{lemma}
Assume that \(y \neq z\), and that \(y \notin \fvs(L)\).
Then the following property of substitutions holds:
\[
M[y := N][z := L] = M[z := L][y := N[z := L]]
\]
\end{lemma}
\begin{proof}
By strong induction on \(M\), avoiding \(y\), \(z\), and the free variables of \(N\) and \(L\).
Normally, the proof proceeds by induction on \(M\), deals easily with the variable and application cases, then becomes concerned with details of name clashing in the binder case.
Consider \(M = \lambda x. A\).
At this point, substitution cannot necessarily be simplified as it may not be capture-avoiding.
However, using the strong induction principle, it is provided that \(x \neq y\), \(x \neq z\), and \(x\) is fresh for both \(N\) and \(L\).
Therefore, the proof follows by simplification directly:
\begin{align*}
\wrap{\lambda x. A}[y := N][z := L]
&= \lambda x. \wrap{A[y := N][z := L]}\\
&= \lambda x. \wrap{A[z := L][y := N[z := L]]}\\
&= \wrap{\lambda x. A}[z := L][y := N[z := L]]
\end{align*}
It can be seen here that by avoiding the names, and hence the problem, the proof is much simpler and the binder case follows directly.
\end{proof}

An important step in showing the subject reduction principle is a result about the effect of substitution on typing, which is used in contracting a \(\beta\)-redex.
This particular lemma also exercises the strong depth-induction principle, combining the ability to avoid name conflicts in the proof, and also to assume that the result holds for any term smaller than the one currently under consideration.

\begin{lemma}
\label{lemma:typing-subst}
Assume that \(N\) has type \(\tau\) under a context \(\Gamma\), and that with \(\Gamma\) extended with \(z\) mapping to \(\tau\), \(M\) has type \(\sigma\).
Then substituting \(z\) for \(N\) in \(M\) has type \(\sigma\) under \(\Gamma\).
\end{lemma}
\begin{proof}
By strong induction on the size of \(M\), avoiding \(z\) and the free variables of \(N\).
As usual, the variable case follows by considering whether or not the variable is \(z\) or not, and the application case follows from the inductive hypothesis.
For the function case, the weakening result about the type system can be used to show that \(\Gamma\{x \mapsto T\} \vdash N : \tau\).

By assumption, \(\Gamma\{z \mapsto \tau\} \vdash \lambda (x:T).A : \sigma\), and hence there is a type \(\sigma'\) such that \(\sigma = T \to \sigma'\), and
\[
\Gamma\{z \mapsto \tau, x \mapsto T\} \vdash A : \sigma'
\]
Hence by the inductive hypotheses, \(\Gamma\{x \mapsto T\} \vdash A[z := N] : \sigma'\), and then
\[
\Gamma \vdash \lambda (x:T). A[z := N] : \sigma
\]
From here the result follows by using the simplification rules for substitution.
\end{proof}

Moving on, I used substitution to define single-step \(\beta\)-reduction with the usual inductive strategy.

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\ beta{\isacharunderscore}reduction\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ beta{\isacharcolon}\ \ {\isachardoublequoteopen}{\isacharparenleft}App\ {\isacharparenleft}Fn\ x\ T\ A{\isacharparenright}\ M{\isacharparenright}\ {\isasymrightarrow}{\isasymbeta}\ {\isacharparenleft}A{\isacharbrackleft}x\ {\isacharcolon}{\isacharcolon}{\isacharequal}\ M{\isacharbrackright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ app{\isadigit{1}}{\isacharcolon}\ \ {\isachardoublequoteopen}A\ {\isasymrightarrow}{\isasymbeta}\ A{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}App\ A\ B{\isacharparenright}\ {\isasymrightarrow}{\isasymbeta}\ {\isacharparenleft}App\ A{\isacharprime}\ B{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ app{\isadigit{2}}{\isacharcolon}\ \ {\isachardoublequoteopen}B\ {\isasymrightarrow}{\isasymbeta}\ B{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}App\ A\ B{\isacharparenright}\ {\isasymrightarrow}{\isasymbeta}\ {\isacharparenleft}App\ A\ B{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fn{\isacharcolon}\ \ \ \ {\isachardoublequoteopen}A\ {\isasymrightarrow}{\isasymbeta}\ A{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Fn\ x\ T\ A{\isacharparenright}\ {\isasymrightarrow}{\isasymbeta}\ {\isacharparenleft}Fn\ x\ T\ A{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

I can now show that types are preserved under single-step reduction, another step towards the subject reduction property.
\begin{lemma}
\label{lemma:preservation'}
Assume that \(M\) is judged to have type \(\tau\) under a context \(\Gamma\).
\(M\) now reduces in a single step to \(M'\).
\(M'\) still has type \(\tau\) under \(\Gamma\).
\end{lemma}
\begin{proof}
Proof proceeds by induction on the derivation of \(\Gamma \vdash M : \tau\).
There are no possible beta-reductions for variables, and only one for functions, so these cases follow easily.
However, there are three possible ways an application can reduce: the left-hand side might reduce, the right-hand side might reduce, or the application may be a redex and reduce by substitution.
By considering these three cases and using the inductive hypotheses (and Lemma \ref{lemma:typing-subst} for the redex case), the result follows immediately in every case.
\end{proof}

\subsection{Normal Forms and the Progress Property}
The normal form predicate on terms may be defined inductively (again), which can then be used to show the progress property, a safety theorem of the type system originally presented by Milner~\cite{milner}, which captures the idea that well-typed terms cannot get ``stuck'': they are either already in a normal form, or can be reduced further.

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\ NF\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ trm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ var{\isacharcolon}\ {\isachardoublequoteopen}NF\ {\isacharparenleft}Var\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ app{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isasymnoteq}\ Fn\ x\ T\ A{\isacharprime}{\isacharsemicolon}\ NF\ A{\isacharsemicolon}\ NF\ B{\isasymrbrakk}\ {\isasymLongrightarrow}\ NF\ {\isacharparenleft}App\ A\ B{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fn{\isacharcolon}\ {\isachardoublequoteopen}NF\ A\ {\isasymLongrightarrow}\ NF\ {\isacharparenleft}Fn\ x\ T\ A{\isacharparenright}{\isachardoublequoteclose}\isanewline
\end{implementation}

\begin{theorem}
\label{theorem:progress}
Assume that \(M\) is well-typed.
Then \(M\) is either in normal form, or there is an \(M'\) such that \(M\) reduces to \(M'\) in one step.
\end{theorem}
\begin{proof}
By induction on \(M\).
The variable case is trivial, and in the binder case by hypothesis either the bound term is in normal form, or it can reduce one further --- in which case either \(M\) is in normal form, or it can reduce further.

In the application case, if either of the application's subterms can reduce, then the application can reduce.
Alternatively, if the application forms a redex, it can also reduce.
However, if none of these conditions hold, then it is in normal form, so in any event the term is in normal form, or can reduce further.
\end{proof}

\subsection{Many-Step Reduction}
Many-step reduction is simply the reflexive, transitive closure of single-step reduction.

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\ beta{\isacharunderscore}reduces\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ reflexive{\isacharcolon}\ \ {\isachardoublequoteopen}M\ {\isasymrightarrow}{\isasymbeta}\isactrlsup {\isacharasterisk}\ M{\isachardoublequoteclose}\isanewline
{\isacharbar}\ transitive{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}M\ {\isasymrightarrow}{\isasymbeta}\isactrlsup {\isacharasterisk}\ M{\isacharprime}{\isacharsemicolon}\ M{\isacharprime}\ {\isasymrightarrow}{\isasymbeta}\ M{\isacharprime}{\isacharprime}{\isasymrbrakk}\ {\isasymLongrightarrow}\ M\ {\isasymrightarrow}{\isasymbeta}\isactrlsup {\isacharasterisk}\ M{\isacharprime}{\isacharprime}{\isachardoublequoteclose}\isanewline
\end{implementation}

Now I can prove the subject-reduction and safety properties for the type system, using Lemma \ref{lemma:preservation'} and the progress property shown in Theorem \ref{theorem:progress}.

\begin{theorem}
Assume that \(M\) has type \(\tau\) in a context \(\Gamma\), and that \(M\) reduces to \(M'\) in an arbitrary number of steps.
Then \(M'\) also has this type under the same context.
\end{theorem}
\begin{proof}
By induction on the many-step reduction of \(M\) to \(M'\).
The reflexive case follows immediately, and the transitive case from the induction hypothesis and Lemma \ref{lemma:preservation'}.
\end{proof}

\begin{theorem}
Assume again that \(M\) is well-typed and \(M\) reduces in many steps to \(M'\).
Then \(M\) is either in normal form, or there is an \(M''\) such that \(M'\) reduces to \(M''\) in exactly one step.
\end{theorem}
\begin{proof}
By induction on the many-step reduction.
In the reflexive case, the results follows immediately from the progress property.
For the transitive case, show that all terms in the transitive relation remain well-typed using the subject-reduction property.
Then apply the progress property.
\end{proof}

I am now finished with the properties I stated in my project proposal.
The task that remains is to show that the inference algorithm is correct with respect to the typing judgements, and hence that the type inference algorithm also has these properties.

\subsection{Inference Correctness}
To show that the inference algorithm is correct, it has to be both \emph{sound} and \emph{complete}.
The algorithm is sound if for any inference it makes, the same judgement can be made in the typing rules.
Conversely, the algorithm is complete if for any judgement that can be made through the typing rules, it can also infer the same type.

\begin{lemma}
The algorithm is sound.
Assume that \(\infertype\wrap{\Gamma, M} = \tau\).
Then \(\Gamma \vdash M : \tau\).
\end{lemma}
\begin{proof}
By induction on \(M\).
In the variable case, \(M\) has an inferred type only if the variable is present in the domain of \(\Gamma\).
But then the typing rule for variables can also deduce this type.
For applications, it follows that the left subterm must have an inferred arrow type, and the right-hand-side a matching type for the arrow.
By the induction hypothesis, these can also be judged using the typing rules, and hence the application rule can be used to produce the result.
Finally, for the binder case, the arrow type can only be inferred if the bound sub-term has an inferred type under the augmented context.
Then by the induction hypothesis and the function rule in the typing judgements, the result follows.
\end{proof}

\begin{lemma}
The algorithm is complete.
Assume that \(\Gamma \vdash M : \tau\).
Then \(\infertype\wrap{\Gamma, M} = \tau\).
\end{lemma}
\begin{proof}
By induction on the typing derivation.
All cases then follow by using the inductive hypothesis and the simplification rules for inference.
\end{proof}

\begin{theorem}
The type inference algorithm is correct.
\end{theorem}
\begin{proof}
Since it is sound and complete, the algorithm is correct, at least by reference to the typing relation.
\end{proof}

\section{Extensions}
\subsection{Unit and Pair Terms}
One extension I added to the project was unit and pair terms, with suitable extensions to the type system.
To do this, I extended the term datatype to include a unit value, a pair constructor, and projection functions for either side of a pair.

\begin{implementation}
\isacommand{datatype}\isamarkupfalse%
\ {\isacharprime}a\ ptrm\ {\isacharequal}\isanewline
\ \ PUnit\isanewline
{\isacharbar}\ PVar\ {\isacharprime}a\isanewline
{\isacharbar}\ PApp\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
{\isacharbar}\ PFn\ {\isacharprime}a\ type\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
{\isacharbar}\ PPair\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
{\isacharbar}\ PFst\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
{\isacharbar}\ PSnd\ {\isachardoublequoteopen}{\isacharprime}a\ ptrm{\isachardoublequoteclose}\isanewline
\end{implementation}

The definition of types also had to be updated to allow typing these new terms.

\begin{implementation}
\isacommand{datatype}\isamarkupfalse%
\ type\ {\isacharequal}\isanewline
\ \ TUnit\isanewline
{\isacharbar}\ TVar\ tvar\isanewline
{\isacharbar}\ TArr\ type\ type\isanewline
{\isacharbar}\ TPair\ type\ type\isanewline
\end{implementation}

Having done this, the main task for this extension was updating all the lemmas and definitions to include the new constructions.
In general this was easier than writing the project over again as the semantics for the new constructions are simpler than e.g. application or binder terms.
Perhaps the most interesting adaptation was the new typing rules, which notably added the constraint that a projection function was only well-typed if it was applied to a term that was a pair type.

One major problem with the combination of this extension and the approach I took with the project as a whole was the number of lemmas that had to be written to determine that any datatype constructor was not equal to a distinct datatype constructor: for example, no pair is equal to a binder.

\subsection{Confluence}
One additional property of the calculus I showed was \emph{confluence}.
The confluence property for a reduction system (such as this one) states that ``if \(A\) reduces in many steps to \(B\) and also to \(C\) (possibly by differing paths), then there is a \(D\) such that \(B\) and \(C\) both reduce in many steps to \(D\)''.

There are several techniques to showing this property for a reduction system.
I took the approach taken by Takahashi~\cite{Takahashi} in his work on the \(\lambda\)-calculus of defining two new inductive definitions, parallel reduction and complete development, to show that \(\beta\)-reduction of terms has the confluence property.
I followed Randy Pollack's excellent overview~\cite{pollack} of the technique and implemented the ideas (for an untyped calculus) in a typed calculus, extended as seen above.

First, I define the relation for parallel reduction (written \(A \gg B\)).
Intuitively, this relation is similar to \(\beta\)-reduction, but at any step where recursive reductions (like reducing the left or right subterm of an application) as well as structural reductions (like contracting a redex) are possible, it performs both at once.

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\ parallel{\isacharunderscore}reduction\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ refl{\isacharcolon}\ {\isachardoublequoteopen}A\ {\isachargreater}{\isachargreater}\ A{\isachardoublequoteclose}\isanewline
{\isacharbar}\ beta{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isachargreater}{\isachargreater}\ A{\isacharprime}{\isacharsemicolon}\ B\ {\isachargreater}{\isachargreater}\ B{\isacharprime}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}App\ {\isacharparenleft}Fn\ x\ T\ A{\isacharparenright}\ B{\isacharparenright}\ {\isachargreater}{\isachargreater}\ {\isacharparenleft}A{\isacharprime}{\isacharbrackleft}x\ {\isacharcolon}{\isacharcolon}{\isacharequal}\ B{\isacharprime}{\isacharbrackright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ eta{\isacharcolon}\ \ {\isachardoublequoteopen}A\ {\isachargreater}{\isachargreater}\ A{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Fn\ x\ T\ A{\isacharparenright}\ {\isachargreater}{\isachargreater}\ {\isacharparenleft}Fn\ x\ T\ A{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ app{\isacharcolon}\ \ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isachargreater}{\isachargreater}\ A{\isacharprime}{\isacharsemicolon}\ B\ {\isachargreater}{\isachargreater}\ B{\isacharprime}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}App\ A\ B{\isacharparenright}\ {\isachargreater}{\isachargreater}\ {\isacharparenleft}App\ A{\isacharprime}\ B{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ pair{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isachargreater}{\isachargreater}\ A{\isacharprime}{\isacharsemicolon}\ B\ {\isachargreater}{\isachargreater}\ B{\isacharprime}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}Pair\ A\ B{\isacharparenright}\ {\isachargreater}{\isachargreater}\ {\isacharparenleft}Pair\ A{\isacharprime}\ B{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fst{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}P\ {\isachargreater}{\isachargreater}\ P{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Fst\ P{\isacharparenright}\ {\isachargreater}{\isachargreater}\ {\isacharparenleft}Fst\ P{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fst{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}A\ {\isachargreater}{\isachargreater}\ A{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Fst\ {\isacharparenleft}Pair\ A\ B{\isacharparenright}{\isacharparenright}\ {\isachargreater}{\isachargreater}\ A{\isacharprime}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ snd{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}P\ {\isachargreater}{\isachargreater}\ P{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Snd\ P{\isacharparenright}\ {\isachargreater}{\isachargreater}\ {\isacharparenleft}Snd\ P{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ snd{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}B\ {\isachargreater}{\isachargreater}\ B{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Snd\ {\isacharparenleft}Pair\ A\ B{\isacharparenright}{\isacharparenright}\ {\isachargreater}{\isachargreater}\ B{\isacharprime}{\isachardoublequoteclose}\isanewline
\end{implementation}

Where the relation was under-specified in the literature (for instance, Pollack's parallel reduction relation does not include rules for evaluating projection functions), I kept with this spirit and reduce the projected term as it is structurally removed from the pair --- note \emph{fst2} and \emph{snd2}.

Next, the complete development relation (written \(A \ggg B\)) is similar to parallel reduction, but written in such a way as to remove any ambiguity as to which rule applies.
For instance, a term \(A\) might be reducible under parallel reduction by some rule to \(A'\).
However, for any given rule it might reduce by, it can also reduce by \emph{refl} to itself.
Complete developments remove this ambiguity.

\begin{implementation}
\isacommand{inductive}\isamarkupfalse%
\ complete{\isacharunderscore}development\ {\isacharcolon}{\isacharcolon}\ {\isachardoublequoteopen}{\isacharprime}a\ trm\ {\isasymRightarrow}\ {\isacharprime}a\ trm\ {\isasymRightarrow}\ bool{\isachardoublequoteclose}\ \isakeyword{where}\isanewline
\ \ unit{\isacharcolon}\ {\isachardoublequoteopen}Unit\ {\isachargreater}{\isachargreater}{\isachargreater}\ Unit{\isachardoublequoteclose}\isanewline
{\isacharbar}\ var{\isacharcolon}\ \ {\isachardoublequoteopen}{\isacharparenleft}Var\ x{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ {\isacharparenleft}Var\ x{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ beta{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isachargreater}{\isachargreater}{\isachargreater}\ A{\isacharprime}{\isacharsemicolon}\ B\ {\isachargreater}{\isachargreater}{\isachargreater}\ B{\isacharprime}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}App\ {\isacharparenleft}Fn\ x\ T\ A{\isacharparenright}\ B{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ {\isacharparenleft}A{\isacharprime}{\isacharbrackleft}x\ {\isacharcolon}{\isacharcolon}{\isacharequal}\ B{\isacharprime}{\isacharbrackright}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ eta{\isacharcolon}\ \ {\isachardoublequoteopen}A\ {\isachargreater}{\isachargreater}{\isachargreater}\ A{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Fn\ x\ T\ A{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ {\isacharparenleft}Fn\ x\ T\ A{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ app{\isacharcolon}\ \ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isachargreater}{\isachargreater}{\isachargreater}\ A{\isacharprime}{\isacharsemicolon}\ B\ {\isachargreater}{\isachargreater}{\isachargreater}\ B{\isacharprime}{\isacharsemicolon}\ {\isacharparenleft}{\isasymAnd}x\ T\ M{\isachardot}\ A\ {\isasymnoteq}\ Fn\ x\ T\ M{\isacharparenright}{\isasymrbrakk}\isanewline
\ \ \ \ \ \ {\isasymLongrightarrow}\ {\isacharparenleft}App\ A\ B{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ {\isacharparenleft}App\ A{\isacharprime}\ B{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ pair{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}A\ {\isachargreater}{\isachargreater}{\isachargreater}\ A{\isacharprime}{\isacharsemicolon}\ B\ {\isachargreater}{\isachargreater}{\isachargreater}\ B{\isacharprime}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}Pair\ A\ B{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ {\isacharparenleft}Pair\ A{\isacharprime}\ B{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fst{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}P\ {\isachargreater}{\isachargreater}{\isachargreater}\ P{\isacharprime}{\isacharsemicolon}\ {\isacharparenleft}{\isasymAnd}A\ B{\isachardot}\ P\ {\isasymnoteq}\ Pair\ A\ B{\isacharparenright}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}Fst\ P{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ {\isacharparenleft}Fst\ P{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ fst{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}A\ {\isachargreater}{\isachargreater}{\isachargreater}\ A{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Fst\ {\isacharparenleft}Pair\ A\ B{\isacharparenright}{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ A{\isacharprime}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ snd{\isadigit{1}}{\isacharcolon}\ {\isachardoublequoteopen}{\isasymlbrakk}P\ {\isachargreater}{\isachargreater}{\isachargreater}\ P{\isacharprime}{\isacharsemicolon}\ {\isacharparenleft}{\isasymAnd}A\ B{\isachardot}\ P\ {\isasymnoteq}\ Pair\ A\ B{\isacharparenright}{\isasymrbrakk}\ {\isasymLongrightarrow}\ {\isacharparenleft}Snd\ P{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ {\isacharparenleft}Snd\ P{\isacharprime}{\isacharparenright}{\isachardoublequoteclose}\isanewline
{\isacharbar}\ snd{\isadigit{2}}{\isacharcolon}\ {\isachardoublequoteopen}B\ {\isachargreater}{\isachargreater}{\isachargreater}\ B{\isacharprime}\ {\isasymLongrightarrow}\ {\isacharparenleft}Snd\ {\isacharparenleft}Pair\ A\ B{\isacharparenright}{\isacharparenright}\ {\isachargreater}{\isachargreater}{\isachargreater}\ B{\isacharprime}{\isachardoublequoteclose}\isanewline
\end{implementation}

It is always the case that a term can be reduced by the complete development relation; this is obvious for parallel reduction (by \emph{refl}), but can also be shown for a complete development.

\begin{lemma}
For any term \(A\), there is an \(A'\) such that \(A \ggg A'\).
\end{lemma}
\begin{proof}
By induction on the structure of \(A\).
In each case, choose a rule based on the structure, then obtain \(A'\) by means of that rule and the induction hypothesis.
\end{proof}

To progress towards the confluence property, I need to show the \emph{diamond property} for parallel reduction, but to get there an auxiliary lemma is required about decomposing a complete development into two parallel reductions.

\begin{lemma}
Suppose \(A \ggg D\) and \(A \gg B\).
Then \(B \gg D\).
\end{lemma}
\begin{proof}
By induction on the derivation of \(A \ggg D\).
For each case, consider how \(A\) (\(A\) and \(D\) are now known from the case) might have reduced under parallel reduction to \(B\), obtain a value for \(B\), then show that \(B \gg D\) by any relevant rule.
\end{proof}

It can now be shown that parallel reduction has the diamond property: that reduction that goes in different directions can always be re-united by another step.

\begin{lemma}
Assume that \(A \gg B\) and \(A \gg C\).
Then there is a \(D\) such that \(B \gg D\) and \(C \gg D\).
\end{lemma}
\begin{proof}
Obtain a \(D\) such that \(A \ggg D\), since such a \(D\) always exists.
Hence by the previous lemma, both \(B \gg D\) and \(C \gg D\).
Thus the diamond property holds for \(\wrap{\gg}\).
\end{proof}

Finally, define the reflexive-transitive closure of \(\wrap{\gg}\), \(\wrap{\gg^*}\) as usual.
It can be shown by a diagram chase that \(\wrap{\gg^*}\) has the diamond property, as seen in Figure \ref{fig:diagram-chase}, so all that remains is to show that the closure of parallel reduction is equivalent to the closure of \(\beta\)-reduction.
This is done by a two-way conversion: converting single-step parallel reduction to many-step \(\beta\)-reduction, and converting \(\beta\)-reduction to single-step parallel reduction.

\begin{figure}
\[
\begin{CD}
A_{00}	@>\gg>>	A_{10}	@>\gg>>	A_{20}	@>\gg>>	\ldots\\
@VV\gg{}V	@VV\gg{}V	@VV\gg{}V\\
A_{01}	@>\gg>>	A_{11}	@>\gg>>	A_{21}	@>\gg>>	\ldots\\
@VV\gg{}V	@VV\gg{}V	@VV\gg{}V\\
A_{02}	@>\gg>>	A_{12}	@>\gg>>	A_{22}	@>\gg>>	\ldots\\
@VV\gg{}V	@VV\gg{}V	@VV\gg{}V\\
\ldots&		&\ldots&	&\ldots\\
\end{CD}
\]
\caption{The diamond property of \(\wrap{\gg^*}\) can be shown using the diamond property of \(\wrap{\gg}\) by induction on the (conceptual) rows of this commutative diagram, then by another induction on the columns.}
\label{fig:diagram-chase}
\end{figure}

\begin{lemma}
If \(A \gg B\), then \(A \to_\beta^* B\).
\end{lemma}
\begin{proof}
By induction on the derivation of \(A \gg B\).
Each case can be converted straightforwardly to a chain of zero or more \(\beta\)-reductions.
\end{proof}

\begin{lemma}
If \(A \to_\beta B\), then \(A \gg B\).
\end{lemma}
\begin{proof}
By induction on the derivation of the \(\beta\)-reduction.
Each case forms (some part of) the corresponding parallel reduction rule, and the \emph{refl} rule of parallel reduction allows reducing subterms that the \(\beta\)-reduction does not reduce.
\end{proof}

\begin{lemma}
\label{lemma:reduction-equivalence}
\(\wrap{\to_\beta^*}\) and \(\wrap{\gg^*}\) are equivalent.
\end{lemma}
\begin{proof}
Directly from the previous pair of lemmas.
\end{proof}

Finally, the confluence property follows from this and the diamond property of the closure of parallel reduction.

\begin{theorem}
Suppose \(A \to_\beta^* B\) and \(A \to_\beta^* C\).
Then there exists a \(D\) such that \(B \to_\beta^* D\) and \(C \to_\beta^* D\).
\end{theorem}
\begin{proof}
By assumption, \(A \gg^* B\) and \(A \gg^* C\), since the two relations are equivalent by Lemma \ref{lemma:reduction-equivalence}.
Then obtain a \(D\) such that \(B \gg^* D\) and \(C \gg^* D\), using the diamond property of \(\wrap{\gg^*}\).
Finally, note that \(B \to_\beta^* D\) and \(C \to_\beta^* D\), again using the equivalence.
\end{proof}
